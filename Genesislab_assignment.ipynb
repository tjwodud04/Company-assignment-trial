{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Genesislab-assignment",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### GenesisLab-Assignment\n",
        "CIFAR-10 classification using FishNet  \n",
        "  \n",
        "Written code file is based on \n",
        "- [2018 Computer Vision Class @ Chulalongkorn University Lab 6 - Convolutional Neural Network](https://github.com/sapjunior/chulacv2018/blob/master/Lab%206%20-%20Convolutional%20Neural%20Network.ipynb)\n",
        "- [FishNet](https://github.com/kevin-ssy/FishNet/tree/b968f0244827e11201471edd8a979bd85027b991)\n",
        "- [Deep Learning Zero to All(Pytorch) 10-6 ResNet for cifar10][1]\n",
        "[1]:https://github.com/deeplearningzerotoall/PyTorch/blob/master/lab-10_6_2_Advance-CNN(ResNet_cifar10).ipynb\n",
        "- [Pytorch tutorial - TRAINING A CLASSIFIER](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html?highlight=cifar)\n",
        "  \n",
        "To understand better, I took a look at\n",
        "- [[PyTorch] 7. Custom Dataset](https://data-panic.tistory.com/21)\n",
        "- [pytorch 직접 데이터 로더 만들고 이미지 학습시키기](https://www.kaeee.de/2021/04/29/pytorch-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%A1%9C%EB%8D%94-%EB%A7%8C%EB%93%A4%EA%B8%B0.html#dataloader%EC%9D%98-%ED%95%84%EC%9A%94%EC%84%B1)\n",
        "- [Quickstart](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html?highlight=cifar)\n",
        "- [FishNet: A Versatile Backbone for Image, Region, and Pixel Level Prediction](https://yckim.medium.com/%EC%A0%95%EB%A6%AC-fishnet-a-versatile-backbone-for-image-region-and-pixel-level-prediction-b86a493f114d)"
      ],
      "metadata": {
        "id": "QQM4Ysv0zk8G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Downloading needed things"
      ],
      "metadata": {
        "id": "3tMY4biq-4_g"
      }
    },
    {
      "metadata": {
        "id": "IdxWIn81cLW7"
      },
      "cell_type": "code",
      "source": [
        "# Install missing packages for Google Colaboratory\n",
        "# !pip3 install torchvision"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cloning FishNet (The paper wrote FishNet code repository at the abstract part)\n",
        "!git clone https://github.com/kevin-ssy/FishNet.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hVTPkP0cOtf",
        "outputId": "b7f42a2e-43c2-4ef7-865a-30218576b870"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'FishNet'...\n",
            "remote: Enumerating objects: 75, done.\u001b[K\n",
            "remote: Total 75 (delta 0), reused 0 (delta 0), pack-reused 75\u001b[K\n",
            "Unpacking objects: 100% (75/75), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import libraries"
      ],
      "metadata": {
        "id": "4J6VxYHv_BYY"
      }
    },
    {
      "metadata": {
        "id": "y8QUqix7a2Pc"
      },
      "cell_type": "code",
      "source": [
        "# based on \"2018 Computer Vision Class @ Chulalongkorn University Lab 6 - Convolutional Neural Network\" resource\n",
        "# import needed libraries\n",
        "import sys\n",
        "import urllib\n",
        "import tarfile\n",
        "import pickle\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Check python and pytorch version"
      ],
      "metadata": {
        "id": "56ppZBKT_OUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"python version: \", sys.version)\n",
        "print(\"pytorch version: \", torch.__version__)"
      ],
      "metadata": {
        "id": "bFO3zmZK2Iqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4193206-ccca-43e6-f760-6cf61765969b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python version:  3.7.12 (default, Sep 10 2021, 00:21:48) \n",
            "[GCC 7.5.0]\n",
            "pytorch version:  1.10.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Function of reading pickle file"
      ],
      "metadata": {
        "id": "l_KK3zed_eY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Based on \"2018 Computer Vision Class @ Chulalongkorn University Lab 6 - Convolutional Neural Network\" resource\n",
        "# Make function of reading pickle file (cifar-10 has 5 data_batch files, one meta file and one test_batch file)\n",
        "def unpickle(file):\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict"
      ],
      "metadata": {
        "id": "7Phy1PVL1SMX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Set device option and seed number"
      ],
      "metadata": {
        "id": "BTn4b-qr_oiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Based on \"Deep Learning Zero to All\" resource\n",
        "# Set device option and seed number\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Set random seed number to fix the result\n",
        "torch.manual_seed(777)\n",
        "if device =='cuda':\n",
        "    torch.cuda.manual_seed_all(777)"
      ],
      "metadata": {
        "id": "-5iTNcpCewST"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Download the cifar-10 dataset and unzip the file"
      ],
      "metadata": {
        "id": "CWSiHdwL_vaN"
      }
    },
    {
      "metadata": {
        "id": "m517oxSFjpXV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "477abe5e-1ed4-41a2-db80-2060d30b140b"
      },
      "cell_type": "code",
      "source": [
        "# Based on \"2018 Computer Vision Class @ Chulalongkorn University Lab 6 - Convolutional Neural Network\" resource\n",
        "# Download CIFAR-10 dataset from https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "urllib.request.urlretrieve ('https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz', 'cifar-10-python.tar.gz')\n",
        "\n",
        "# Unzip the file\n",
        "with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
        "    tar.extractall()\n",
        "    \n",
        "# Show files in extract directory\n",
        "!ls cifar-10-batches-py/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batches.meta  data_batch_2  data_batch_4  readme.html\n",
            "data_batch_1  data_batch_3  data_batch_5  test_batch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Call the model (FishNet)"
      ],
      "metadata": {
        "id": "bdi2L-4H_484"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Based on \"FishNet\" resource\n",
        "# Import the model based on the GitHub explanation (has fishnet99, fishnet150, fishnet201)\n",
        "from FishNet.models.net_factory import fishnet150\n",
        "\n",
        "fishnet = fishnet150()"
      ],
      "metadata": {
        "id": "X0ksaMybcaDc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(fishnet)"
      ],
      "metadata": {
        "id": "LSSwFUxzhdgm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Function of data transformation"
      ],
      "metadata": {
        "id": "Bliry_9U_93I"
      }
    },
    {
      "metadata": {
        "id": "0M8wOQVLT_7Q"
      },
      "cell_type": "code",
      "source": [
        "# Based on \"2018 Computer Vision Class @ Chulalongkorn University Lab 6 - Convolutional Neural Network\" resource\n",
        "# Utilize the downloaded dataset\n",
        "class CIFAR10Loader(data.Dataset):\n",
        "    def __init__(self, cifarDatasetPath='cifar-10-batches-py/',train=True, transform=None):\n",
        "      self.transform = transform\n",
        "      \n",
        "      # For train data files (data_batch_1~data_batch_5)\n",
        "      if train:\n",
        "        self.cifarImages = np.empty((0,3072), dtype=np.uint8)\n",
        "        self.cifarLabels = np.empty((0,), dtype=np.uint8)\n",
        "\n",
        "        for batchNo in range(1,6):\n",
        "          dataDict = unpickle(cifarDatasetPath+'/data_batch_'+str(batchNo))\n",
        "          self.cifarImages = np.vstack((self.cifarImages, dataDict[b'data']))\n",
        "          self.cifarLabels = np.hstack((self.cifarLabels, dataDict[b'labels']))\n",
        "      \n",
        "      # For test data file\n",
        "      else:\n",
        "        dataDict = unpickle(cifarDatasetPath+'/test_batch')\n",
        "        self.cifarImages = dataDict[b'data']\n",
        "        self.cifarLabels = np.array(dataDict[b'labels'])\n",
        "        \n",
        "      # Transfrom from (x,3072) ==> (32,32,3,x)\n",
        "      self.cifarImages = self.cifarImages.reshape(-1,3,32,32).transpose(2,3,1,0)\n",
        "\n",
        "    # __getitem__은 데이터셋이 가지고있는 데이터를 리턴하는 기능을 합니다. ([PyTorch] 7. Custom Dataset resource)\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.cifarImages[:,:,:,idx]\n",
        "        label = self.cifarLabels[idx]\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    # cifar10의 경우 트레이닝, 혹은 테스트 셋의 전체 이미지의 갯수가 될 것이다.(pytorch 직접 데이터 로더 만들고 이미지 학습시키기 resource)\n",
        "    def __len__(self):\n",
        "        return self.cifarLabels.shape[0]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NQ1wd5wwcSob"
      },
      "cell_type": "code",
      "source": [
        "# Based on \"2018 Computer Vision Class @ Chulalongkorn University Lab 6 - Convolutional Neural Network\" resource\n",
        "def transformer(image):\n",
        "    image = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.406, 0.456), (0.229, 0.225, 0.224)),\n",
        "        #transforms.RandomHorizontalFlip(p=0.5),\n",
        "    ])(image)\n",
        "    return image"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZioPEbrSYbg5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b32c70c-bba7-4caf-bc9e-7248f46543a3"
      },
      "cell_type": "code",
      "source": [
        "# Based on \"2018 Computer Vision Class @ Chulalongkorn University Lab 6 - Convolutional Neural Network\" resource\n",
        "cifar10Train = CIFAR10Loader(transform = transformer)\n",
        "cifar10Test = CIFAR10Loader(train = False, transform = transformer)\n",
        "cifar10TrainLoader = data.DataLoader(dataset=cifar10Train, batch_size=128,num_workers=4,shuffle=True)\n",
        "cifar10TestLoader = data.DataLoader(dataset=cifar10Train, batch_size=128,num_workers=4,shuffle=False)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### model, optimization and loss function"
      ],
      "metadata": {
        "id": "rngz6wzWAjuH"
      }
    },
    {
      "metadata": {
        "id": "cX1XgKN-ZkjL"
      },
      "cell_type": "code",
      "source": [
        "# based on \"2018 Computer Vision Class @ Chulalongkorn University Lab 6 - Convolutional Neural Network\" resource\n",
        "# make network, loss function and optimizer\n",
        "net = fishnet.to(device)\n",
        "net.train()\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=0.0001)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train"
      ],
      "metadata": {
        "id": "quQuE4JeAYT1"
      }
    },
    {
      "metadata": {
        "id": "pQmJJh80aVyw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5be18af7-4a1a-419d-e73c-b30fa48798a5"
      },
      "cell_type": "code",
      "source": [
        "# based on \"2018 Computer Vision Class @ Chulalongkorn University Lab 6 - Convolutional Neural Network\" resource\n",
        "print('== Start Training ==')\n",
        "\n",
        "bestLoss = float('Inf')\n",
        "totalEpoch = 20\n",
        "outputModelFile = 'bestCIFAR10.pth'\n",
        "\n",
        "for epoch in range(0,totalEpoch):\n",
        "  totalLoss = 0\n",
        "  for batchIdx,(image,label) in enumerate(cifar10TrainLoader):\n",
        "    image, label = image.to(device), label.to(device)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # forward + backward + optimize\n",
        "    output = net(image)\n",
        "    loss = criterion(output, label)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    totalLoss+=loss.item()\n",
        "    \n",
        "  # Loss decrease, we should save the model\n",
        "  totalLoss = totalLoss/len(cifar10TrainLoader)\n",
        "  if totalLoss < bestLoss:\n",
        "    print('Saving..')\n",
        "    bestLoss = totalLoss\n",
        "    state = {\n",
        "        'model': net.state_dict(),\n",
        "        'loss': bestLoss,\n",
        "        'epoch': epoch,\n",
        "    }\n",
        "    torch.save(state, outputModelFile)\n",
        "    \n",
        "    \n",
        "  print(epoch+1,'/',str(totalEpoch),'Batch Loss:',totalLoss)\n",
        "  \n",
        "print('== Training Finish ==')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Start Training ==\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving..\n",
            "1 / 20 Batch Loss: 1.6521334151172882\n",
            "Saving..\n",
            "2 / 20 Batch Loss: 1.1977402046513375\n",
            "Saving..\n",
            "3 / 20 Batch Loss: 0.9823411555241441\n",
            "Saving..\n",
            "4 / 20 Batch Loss: 0.8959156546141486\n",
            "Saving..\n",
            "5 / 20 Batch Loss: 0.7285186133878615\n",
            "Saving..\n",
            "6 / 20 Batch Loss: 0.6114533246325715\n",
            "Saving..\n",
            "7 / 20 Batch Loss: 0.5144982699238126\n",
            "Saving..\n",
            "8 / 20 Batch Loss: 0.41253555137330616\n",
            "Saving..\n",
            "9 / 20 Batch Loss: 0.3337600011273723\n",
            "Saving..\n",
            "10 / 20 Batch Loss: 0.283700877348023\n",
            "Saving..\n",
            "11 / 20 Batch Loss: 0.2299967078525392\n",
            "Saving..\n",
            "12 / 20 Batch Loss: 0.19867395245663041\n",
            "Saving..\n",
            "13 / 20 Batch Loss: 0.18594511469726063\n",
            "Saving..\n",
            "14 / 20 Batch Loss: 0.17142801642265465\n",
            "Saving..\n",
            "15 / 20 Batch Loss: 0.16046736099759637\n",
            "Saving..\n",
            "16 / 20 Batch Loss: 0.13663208576590966\n",
            "17 / 20 Batch Loss: 0.14646968798106894\n",
            "Saving..\n",
            "18 / 20 Batch Loss: 0.1318818741213635\n",
            "Saving..\n",
            "19 / 20 Batch Loss: 0.12874162203305975\n",
            "Saving..\n",
            "20 / 20 Batch Loss: 0.12701801150141623\n",
            "== Training Finish ==\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test"
      ],
      "metadata": {
        "id": "mIeiH0gbAe5k"
      }
    },
    {
      "metadata": {
        "id": "4Q62cScy42Yl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "968f7992-cb70-475b-8ef9-ff2e9c526cd4"
      },
      "cell_type": "code",
      "source": [
        "# Based on \"Pytorch tutorial - TRAINING A CLASSIFIER\" and \"Deep Learning Zero to All\" resources\n",
        "# Calculate test accuracy\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in cifar10TestLoader:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = fishnet(images)\n",
        "        \n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        \n",
        "        total += labels.size(0)\n",
        "        \n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 97 %\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "4txczyJexYXM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95189b14-bc2c-4928-a3d9-b23dd9a3332a"
      },
      "cell_type": "code",
      "source": [
        "# Based on \"Pytorch tutorial - TRAINING A CLASSIFIER\" resource\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# prepare to count predictions for each class\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    for data in cifar10TestLoader:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = fishnet(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname, accuracy))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for class plane is: 97.4 %\n",
            "Accuracy for class car   is: 99.0 %\n",
            "Accuracy for class bird  is: 96.4 %\n",
            "Accuracy for class cat   is: 96.2 %\n",
            "Accuracy for class deer  is: 94.7 %\n",
            "Accuracy for class dog   is: 96.5 %\n",
            "Accuracy for class frog  is: 97.7 %\n",
            "Accuracy for class horse is: 97.7 %\n",
            "Accuracy for class ship  is: 98.7 %\n",
            "Accuracy for class truck is: 96.5 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2dfOJm7AcBWr"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}